#!/usr/bin/env python3
import json
import os

# Define the cells
system_setup_cell = {
    "cell_type": "code",
    "metadata": {
        "id": "KsE3HfJk4r_b",
        "cellView": "form"
    },
    "source": [
        "# @title System Setup\n",
        "# Install required system packages\n",
        "print(\"Starting system setup...\")\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq -y python3-tk alsa-utils libasound2-plugins\n",
        "print(\"System packages installed.\")\n",
        "\n",
        "# Create dummy ALSA config to redirect sound to null device (prevents ALSA errors)\n",
        "print(\"Creating dummy ALSA config...\")\n",
        "alsa_config_content = \"\"\"\n",
        "pcm.!default {\n",
        "    type null\n",
        "}\n",
        "ctl.!default {\n",
        "    type null\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Write to home directory using os.path.expanduser to handle ~ correctly\n",
        "import os\n",
        "asoundrc_path = os.path.expanduser(\"~/.asoundrc\")\n",
        "try:\n",
        "    with open(asoundrc_path, \"w\") as f:\n",
        "        f.write(alsa_config_content)\n",
        "    print(f\"Dummy ALSA config created at {asoundrc_path}\")\n",
        "    # Verify file was created\n",
        "    !cat ~/.asoundrc\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not create ALSA config: {e}\")\n",
        "    # Try alternative approach with shell command\n",
        "    !echo \"pcm.!default { type null }\\nctl.!default { type null }\" > ~/.asoundrc\n",
        "    print(\"Attempted alternative method to create ALSA config\")\n",
        "\n",
        "# Set XDG_RUNTIME_DIR to suppress warnings\n",
        "os.environ['XDG_RUNTIME_DIR'] = '/tmp/runtime-root'\n",
        "!mkdir -p /tmp/runtime-root\n",
        "!chmod 700 /tmp/runtime-root\n",
        "\n",
        "print(\"System setup complete.\")"
    ],
    "execution_count": None,
    "outputs": []
}

dependencies_cell = {
    "cell_type": "code",
    "metadata": {
        "id": "QdLhnsXk4r_c",
        "cellView": "form"
    },
    "source": [
        "# @title Initialize Dependencies\n",
        "\n",
        "# @markdown Enter your Gemini API key (optional - you can also enter it in the next cells)\n",
        "TEMP_GEMINI_API_KEY = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# Clone repository and install dependencies\n",
        "import os\n",
        "if not os.path.exists('/content/UnQTube-'):\n",
        "  !git clone https://github.com/Sandeepgaddam5432/UnQTube-.git\n",
        "  %cd /content/UnQTube-/\n",
        "else:\n",
        "  %cd /content/UnQTube-/\n",
        "  !git pull\n",
        "\n",
        "# Install all dependencies from requirements.txt\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# Store API key for next cells if provided\n",
        "if TEMP_GEMINI_API_KEY:\n",
        "    os.environ[\"GEMINI_API_KEY_TEMP\"] = TEMP_GEMINI_API_KEY\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(\"=\"*80)\n",
        "print(\"IMPORTANT: After installing dependencies, you may need to restart the runtime.\")\n",
        "print(\"If you see a 'Restart Runtime' button above, please click it or go to Runtime -> Restart Runtime\")\n",
        "print(\"After restarting, re-run all cells from the beginning.\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n\\n\")"
    ],
    "execution_count": None,
    "outputs": []
}

gemini_config_cell = {
    "cell_type": "code",
    "metadata": {
        "id": "fkX3mjWK72G1",
        "cellView": "form"
    },
    "source": [
        "# @title Check and Configure Gemini\n",
        "\n",
        "# @markdown Enter a custom Gemini model name if you have a specific one you know works (optional)\n",
        "CUSTOM_GEMINI_MODEL = \"\" #@param {type:\"string\"}\n",
        "# @markdown Check this if your custom model requires the v1beta API endpoint\n",
        "CUSTOM_MODEL_USES_BETA = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Check if the Gemini API module is installed and working\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/UnQTube-/')\n",
        "\n",
        "try:\n",
        "    from lib.gemini_api import list_available_gemini_models, get_gemini_key, generate_script_with_gemini, is_beta_model\n",
        "    \n",
        "    # Get API key from environment or previous cell\n",
        "    api_key = os.environ.get(\"GEMINI_API_KEY_TEMP\", get_gemini_key())\n",
        "    \n",
        "    # Process custom model if provided\n",
        "    if CUSTOM_GEMINI_MODEL:\n",
        "        print(f\"Using custom model: {CUSTOM_GEMINI_MODEL}\")\n",
        "        # Ensure the model has the 'models/' prefix if not already present\n",
        "        if not CUSTOM_GEMINI_MODEL.startswith(\"models/\"):\n",
        "            custom_model_full = f\"models/{CUSTOM_GEMINI_MODEL}\"\n",
        "        else:\n",
        "            custom_model_full = CUSTOM_GEMINI_MODEL\n",
        "            \n",
        "        # Save to environment for other cells\n",
        "        os.environ[\"CUSTOM_GEMINI_MODEL\"] = custom_model_full\n",
        "        os.environ[\"CUSTOM_MODEL_USES_BETA\"] = \"true\" if CUSTOM_MODEL_USES_BETA else \"false\"\n",
        "    \n",
        "    if api_key:\n",
        "        print(f\"Checking available Gemini models with your API key...\")\n",
        "        try:\n",
        "            # Get FILTERED list of text generation models with strict filtering\n",
        "            models = list_available_gemini_models(api_key)\n",
        "            print(f\"\\nAvailable Gemini models for text generation:\")\n",
        "            for model in models:\n",
        "                # For display, we'll show a cleaner version without the prefix\n",
        "                display_name = model.replace('models/', '')\n",
        "                # Indicate if model uses v1beta API\n",
        "                api_version = \"v1beta\" if is_beta_model(model) else \"v1\"\n",
        "                print(f\"- {display_name} (API name: {model}, API version: {api_version})\")\n",
        "                \n",
        "            # Make sure our known working model is included\n",
        "            known_working_model = \"models/gemini-2.5-flash-preview-04-17\"\n",
        "            if known_working_model not in models:\n",
        "                print(f\"Adding known working model: {known_working_model} (API version: v1beta)\")\n",
        "                models.append(known_working_model)\n",
        "                \n",
        "            if not models:\n",
        "                print(\"\\nWarning: No Gemini text generation models found for your API key!\")\n",
        "                print(\"Using default models, but they may not work with your API key.\")\n",
        "                # Use reliable default models as fallback\n",
        "                models = [\"models/gemini-pro\", \"models/gemini-1.5-pro\", \"models/gemini-2.5-flash-preview-04-17\"]\n",
        "                \n",
        "            # Add custom model to the beginning of the list if provided\n",
        "            if CUSTOM_GEMINI_MODEL and custom_model_full not in models:\n",
        "                models.insert(0, custom_model_full)\n",
        "                print(f\"Added custom model to available models list: {custom_model_full}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error listing Gemini models: {e}\")\n",
        "            print(\"Using reliable default models instead.\")\n",
        "            models = [\"models/gemini-pro\", \"models/gemini-1.5-pro\", \"models/gemini-2.5-flash-preview-04-17\"]\n",
        "            \n",
        "            # Still add custom model if provided\n",
        "            if CUSTOM_GEMINI_MODEL and custom_model_full not in models:\n",
        "                models.insert(0, custom_model_full)\n",
        "                print(f\"Added custom model to default models list: {custom_model_full}\")\n",
        "    else:\n",
        "        print(\"No API key found. You'll need to provide one in the video generation cells below.\")\n",
        "        models = [\"models/gemini-pro\", \"models/gemini-1.5-pro\", \"models/gemini-2.5-flash-preview-04-17\"]\n",
        "        \n",
        "        # Still add custom model if provided\n",
        "        if CUSTOM_GEMINI_MODEL:\n",
        "            models.insert(0, custom_model_full)\n",
        "            print(f\"Added custom model to default models list: {custom_model_full}\")\n",
        "        \n",
        "    # Save models to environment variable for use in next cells\n",
        "    os.environ[\"AVAILABLE_GEMINI_MODELS\"] = \",\".join(models)\n",
        "    \n",
        "    # Test Gemini API connectivity\n",
        "    if api_key and models:\n",
        "        print(\"\\nTesting Gemini API connectivity...\")\n",
        "        \n",
        "        # Try models in this priority order:\n",
        "        # 1. Custom model if provided\n",
        "        # 2. Known working model (gemini-2.5-flash-preview-04-17)\n",
        "        # 3. Other models from the filtered list\n",
        "        \n",
        "        test_models = []\n",
        "        \n",
        "        # Add custom model first if provided\n",
        "        if CUSTOM_GEMINI_MODEL:\n",
        "            test_models.append(custom_model_full)\n",
        "        \n",
        "        # Add known working model next\n",
        "        known_working_model = \"models/gemini-2.5-flash-preview-04-17\"\n",
        "        if known_working_model not in test_models:\n",
        "            test_models.append(known_working_model)\n",
        "        \n",
        "        # Add other models\n",
        "        for model in models:\n",
        "            if model not in test_models:\n",
        "                test_models.append(model)\n",
        "        \n",
        "        # Test each model until one works\n",
        "        success = False\n",
        "        working_model = None\n",
        "        \n",
        "        for test_model in test_models:\n",
        "            print(f\"Testing with model: {test_model}\")\n",
        "            \n",
        "            # Override the model in config temporarily for this test\n",
        "            config_path = \"/content/UnQTube-/config.txt\"\n",
        "            if os.path.exists(config_path):\n",
        "                with open(config_path, \"r\") as f_read:\n",
        "                    lines = f_read.readlines()\n",
        "                \n",
        "                updated_lines = []\n",
        "                for line in lines:\n",
        "                    if line.startswith(\"gemini_model\"):\n",
        "                        updated_lines.append(f\"gemini_model = {test_model}\\n\")\n",
        "                    else:\n",
        "                        updated_lines.append(line)\n",
        "                \n",
        "                with open(config_path, \"w\") as f_write:\n",
        "                    f_write.writelines(updated_lines)\n",
        "            \n",
        "            try:\n",
        "                test_result = generate_script_with_gemini(\"Hello, please respond with 'API test successful'\", api_key)\n",
        "                print(f\"API test result: {test_result}\")\n",
        "                print(f\"Gemini API connectivity verified with model: {test_model}!\")\n",
        "                success = True\n",
        "                working_model = test_model\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"Test failed with model {test_model}: {e}\")\n",
        "                # Continue to the next model\n",
        "        \n",
        "        if success and working_model:\n",
        "            print(f\"\\nSUCCESS: Found working model: {working_model}\")\n",
        "            \n",
        "            # Move the working model to the top of the list\n",
        "            if working_model in models:\n",
        "                models.remove(working_model)\n",
        "            models.insert(0, working_model)\n",
        "            \n",
        "            # Update environment variable with reordered list\n",
        "            os.environ[\"AVAILABLE_GEMINI_MODELS\"] = \",\".join(models)\n",
        "            os.environ[\"WORKING_GEMINI_MODEL\"] = working_model\n",
        "            \n",
        "            # Update config.txt with the working model\n",
        "            config_path = \"/content/UnQTube-/config.txt\"\n",
        "            if os.path.exists(config_path):\n",
        "                with open(config_path, \"r\") as f_read:\n",
        "                    lines = f_read.readlines()\n",
        "                \n",
        "                updated_lines = []\n",
        "                model_updated = False\n",
        "                \n",
        "                for line in lines:\n",
        "                    if line.startswith(\"gemini_model\"):\n",
        "                        updated_lines.append(f\"gemini_model = {working_model}\\n\")\n",
        "                        model_updated = True\n",
        "                    else:\n",
        "                        updated_lines.append(line)\n",
        "                \n",
        "                if not model_updated:\n",
        "                    updated_lines.append(f\"gemini_model = {working_model}\\n\")\n",
        "                \n",
        "                with open(config_path, \"w\") as f_write:\n",
        "                    f_write.writelines(updated_lines)\n",
        "        else:\n",
        "            print(\"\\nWarning: Could not find a working Gemini model for your API key.\")\n",
        "            print(\"Please try providing a custom model in the field above if you know one that works.\")\n",
        "            print(\"The specified model 'gemini-2.5-flash-preview-04-17' with v1beta endpoint should work with most API keys.\")\n",
        "            print(\"Video generation may still work with fallback methods, but script quality will be lower.\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error importing Gemini module: {e}\")\n",
        "    print(\"This is expected if you just installed the dependencies and need to restart the runtime.\")\n",
        "    print(\"Please follow the instructions from the previous cell to restart the runtime.\")"
    ],
    "execution_count": None,
    "outputs": []
}

long_video_cell = {
    "cell_type": "code",
    "metadata": {
        "id": "bBcsxIdM1Lp7",
        "cellView": "form"
    },
    "source": [
        "# @title Long Video\n",
        "\n",
        "# Get available models from previous cell or use defaults\n",
        "import os\n",
        "try:\n",
        "    # First check if we have a confirmed working model from previous testing\n",
        "    working_model = os.environ.get(\"WORKING_GEMINI_MODEL\", \"\")\n",
        "    if working_model:\n",
        "        print(f\"Using previously verified working model: {working_model}\")\n",
        "        available_models = [working_model]\n",
        "        # Add other models after the working one\n",
        "        other_models = os.environ.get(\"AVAILABLE_GEMINI_MODELS\", \"\").split(\",\")\n",
        "        for model in other_models:\n",
        "            if model and model != working_model and model not in available_models:\n",
        "                available_models.append(model)\n",
        "    else:\n",
        "        # Get the filtered list of text-generation models from the environment variable\n",
        "        available_models = os.environ.get(\"AVAILABLE_GEMINI_MODELS\", \"models/gemini-pro,models/gemini-1.5-pro,models/gemini-2.5-flash-preview-04-17\").split(\",\")\n",
        "    \n",
        "    # Check for custom model\n",
        "    custom_model = os.environ.get(\"CUSTOM_GEMINI_MODEL\", \"\")\n",
        "    if custom_model and custom_model not in available_models:\n",
        "        available_models.insert(0, custom_model)\n",
        "        print(f\"Using custom model: {custom_model}\")\n",
        "    \n",
        "    # Create a display-friendly version of model names for the dropdown\n",
        "    model_options = [model.replace('models/', '') for model in available_models if model]\n",
        "    # Create a mapping from display name to full model name\n",
        "    model_mapping = dict(zip(model_options, [m for m in available_models if m]))\n",
        "    \n",
        "    print(f\"Available Gemini text generation models: {', '.join(model_options)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error processing model list: {e}\")\n",
        "    available_models = [\"models/gemini-pro\", \"models/gemini-1.5-pro\", \"models/gemini-2.5-flash-preview-04-17\"]\n",
        "    model_options = [\"gemini-pro\", \"gemini-1.5-pro\", \"gemini-2.5-flash-preview-04-17\"]\n",
        "    model_mapping = {\"gemini-pro\": \"models/gemini-pro\", \"gemini-1.5-pro\": \"models/gemini-1.5-pro\", \"gemini-2.5-flash-preview-04-17\": \"models/gemini-2.5-flash-preview-04-17\"}\n",
        "\n",
        "# @markdown Enter video topic. Example: survival video game\n",
        "topic = \"survival video game\" # @param {type:\"string\"}\n",
        "# @markdown general topic you want to make a video about.Example: video game, food, city, person and...\n",
        "general_topic = \"video game\" # @param {type:\"string\"}\n",
        "# @markdown video time in minute\n",
        "time = \"2\" # @param {type:\"string\"}\n",
        "# @markdown do you want intro with video instead photo?\n",
        "intro_video = \"no\" # @param [\"yes\",\"no\"]\n",
        "# @markdown if yes , get API from www.pexels.com\n",
        "pexels_api = \"\" # @param {type:\"string\"}\n",
        "# @markdown video language\n",
        "language = \"english\" # @param [\"english\", \"spanish\", \"french\", \"german\", \"italian\", \"portuguese\", \"russian\", \"japanese\", \"korean\", \"chinese\"]\n",
        "# @markdown Use multiple speakers in video\n",
        "multi_speaker = \"no\" # @param [\"yes\",\"no\"]\n",
        "\n",
        "# @markdown Use Gemini API for enhanced script generation (optional, strongly recommended)\n",
        "use_gemini = \"yes\" # @param [\"yes\",\"no\"]\n",
        "# @markdown Gemini API Key\n",
        "GEMINI_API_KEY = \"\" #@param {type:\"string\"}\n",
        "# @markdown Select Gemini model (display name without 'models/' prefix)\n",
        "GEMINI_MODEL_DISPLAY = model_options[0] if model_options else \"gemini-2.5-flash-preview-04-17\" #@param {type:\"string\"}\n",
        "# @markdown Optional: Enter a custom Gemini model name if it's not in the dropdown list\n",
        "CUSTOM_GEMINI_MODEL = \"\" #@param {type:\"string\"}\n",
        "# @markdown Check this if your custom model requires the v1beta API endpoint\n",
        "CUSTOM_MODEL_USES_BETA = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Process custom model input if provided\n",
        "if CUSTOM_GEMINI_MODEL:\n",
        "    print(f\"Using custom model: {CUSTOM_GEMINI_MODEL}\")\n",
        "    # Ensure the model has the 'models/' prefix if not already present\n",
        "    if not CUSTOM_GEMINI_MODEL.startswith(\"models/\"):\n",
        "        GEMINI_MODEL_NAME = f\"models/{CUSTOM_GEMINI_MODEL}\"\n",
        "    else:\n",
        "        GEMINI_MODEL_NAME = CUSTOM_GEMINI_MODEL\n",
        "else:\n",
        "    # Get the actual full model name with prefix from our mapping\n",
        "    GEMINI_MODEL_NAME = model_mapping.get(GEMINI_MODEL_DISPLAY, \"models/gemini-2.5-flash-preview-04-17\")\n",
        "    \n",
        "print(f\"Selected model: {GEMINI_MODEL_NAME.replace('models/', '')} (Full API name: {GEMINI_MODEL_NAME})\")\n",
        "\n",
        "# Update config.txt with Gemini API Key and model from form\n",
        "gemini_api_key_from_form = GEMINI_API_KEY # Gets value from the form field\n",
        "gemini_model_from_form = GEMINI_MODEL_NAME # Gets full model name with prefix\n",
        "use_gemini_setting = \"yes\" if use_gemini == \"yes\" else \"no\"\n",
        "\n",
        "# Check for temp API key from cell 2\n",
        "if not gemini_api_key_from_form and \"GEMINI_API_KEY_TEMP\" in os.environ:\n",
        "    gemini_api_key_from_form = os.environ[\"GEMINI_API_KEY_TEMP\"]\n",
        "    print(f\"Using Gemini API Key from previous cell\")\n",
        "\n",
        "if gemini_api_key_from_form and use_gemini_setting == \"yes\":\n",
        "    print(f\"Configuring Gemini with model: {gemini_model_from_form}\")\n",
        "    config_path = \"/content/UnQTube-/config.txt\"\n",
        "    try:\n",
        "        with open(config_path, \"r\") as f_read:\n",
        "            lines = f_read.readlines()\n",
        "        \n",
        "        updated_lines = []\n",
        "        key_updated = False\n",
        "        model_updated = False\n",
        "        gemini_enabled = False\n",
        "\n",
        "        for line in lines:\n",
        "            stripped_line = line.strip()\n",
        "            if stripped_line.startswith(\"gemini_api\"):\n",
        "                updated_lines.append(f\"gemini_api = {gemini_api_key_from_form}\\n\")\n",
        "                key_updated = True\n",
        "            elif stripped_line.startswith(\"gemini_model\"):\n",
        "                updated_lines.append(f\"gemini_model = {gemini_model_from_form}\\n\")\n",
        "                model_updated = True\n",
        "            elif stripped_line.startswith(\"use_gemini\"):\n",
        "                updated_lines.append(f\"use_gemini = {use_gemini_setting}\\n\")\n",
        "                gemini_enabled = True\n",
        "            else:\n",
        "                updated_lines.append(line)\n",
        "        \n",
        "        # If keys were not in original file, add them\n",
        "        if not key_updated:\n",
        "            updated_lines.append(f\"gemini_api = {gemini_api_key_from_form}\\n\")\n",
        "        if not model_updated:\n",
        "            updated_lines.append(f\"gemini_model = {gemini_model_from_form}\\n\")\n",
        "        if not gemini_enabled:\n",
        "            updated_lines.append(f\"use_gemini = {use_gemini_setting}\\n\")\n",
        "\n",
        "        with open(config_path, \"w\") as f_write:\n",
        "            f_write.writelines(updated_lines)\n",
        "        print(f\"Updated config.txt with Gemini settings\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Could not update config: {e}\")\n",
        "else:\n",
        "    # Ensure Gemini is disabled if no key is provided or user disabled it\n",
        "    print(f\"Gemini AI is {'disabled' if use_gemini_setting == 'no' else 'enabled but missing API key'}\")\n",
        "    config_path = \"/content/UnQTube-/config.txt\"\n",
        "    try:\n",
        "        with open(config_path, \"r\") as f_read:\n",
        "            lines = f_read.readlines()\n",
        "        \n",
        "        updated_lines = []\n",
        "        for line in lines:\n",
        "            stripped_line = line.strip()\n",
        "            if stripped_line.startswith(\"gemini_api\"):\n",
        "                updated_lines.append(\"gemini_api = \\n\") \n",
        "            elif stripped_line.startswith(\"use_gemini\"):\n",
        "                updated_lines.append(\"use_gemini = no\\n\")\n",
        "            else:\n",
        "                updated_lines.append(line)\n",
        "        \n",
        "        with open(config_path, \"w\") as f_write:\n",
        "            f_write.writelines(updated_lines)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Could not update config: {e}\")\n",
        "\n",
        "# Run the video generation command\n",
        "!python video.py -topic \"$topic\" -general_topic \"$general_topic\" -time \"$time\" -intro_video \"$intro_video\" -pexels_api \"$pexels_api\" -language \"$language\" -multi_speaker \"$multi_speaker\"\n",
        "\n",
        "# Display and offer download of the generated video if it exists\n",
        "from IPython.display import HTML, Video\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Find the generated video file\n",
        "import glob\n",
        "video_files = glob.glob(\"/content/UnQTube_*.mp4\")\n",
        "\n",
        "if video_files:\n",
        "    video_path = video_files[0]\n",
        "    print(f\"\\n\\nVideo generation completed! File: {video_path}\")\n",
        "    \n",
        "    # Display the video\n",
        "    display(Video(video_path, width=600))\n",
        "    \n",
        "    # Offer download\n",
        "    try:\n",
        "        files.download(video_path)\n",
        "    except Exception as e:\n",
        "        print(f\"\\nTo download the video, use the three-dot menu in the file browser panel and select '{video_path}'\")\n",
        "else:\n",
        "    print(\"\\n\\nNo video file was generated. Check the output above for errors.\")"
    ],
    "execution_count": None,
    "outputs": []
}

short_video_cell = {
    "cell_type": "code",
    "metadata": {
        "id": "2H5MJ0ZV61DD",
        "cellView": "form"
    },
    "source": [
        "# @title Short Video\n",
        "\n",
        "# Get available models from previous cell or use defaults\n",
        "import os\n",
        "try:\n",
        "    # First check if we have a confirmed working model from previous testing\n",
        "    working_model = os.environ.get(\"WORKING_GEMINI_MODEL\", \"\")\n",
        "    if working_model:\n",
        "        print(f\"Using previously verified working model: {working_model}\")\n",
        "        available_models = [working_model]\n",
        "        # Add other models after the working one\n",
        "        other_models = os.environ.get(\"AVAILABLE_GEMINI_MODELS\", \"\").split(\",\")\n",
        "        for model in other_models:\n",
        "            if model and model != working_model and model not in available_models:\n",
        "                available_models.append(model)\n",
        "    else:\n",
        "        # Get the filtered list of text-generation models from the environment variable\n",
        "        available_models = os.environ.get(\"AVAILABLE_GEMINI_MODELS\", \"models/gemini-pro,models/gemini-1.5-pro,models/gemini-2.5-flash-preview-04-17\").split(\",\")\n",
        "    \n",
        "    # Check for custom model\n",
        "    custom_model = os.environ.get(\"CUSTOM_GEMINI_MODEL\", \"\")\n",
        "    if custom_model and custom_model not in available_models:\n",
        "        available_models.insert(0, custom_model)\n",
        "        print(f\"Using custom model: {custom_model}\")\n",
        "    \n",
        "    # Create a display-friendly version of model names for the dropdown\n",
        "    model_options = [model.replace('models/', '') for model in available_models if model]\n",
        "    # Create a mapping from display name to full model name\n",
        "    model_mapping = dict(zip(model_options, [m for m in available_models if m]))\n",
        "    \n",
        "    print(f\"Available Gemini text generation models: {', '.join(model_options)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error processing model list: {e}\")\n",
        "    available_models = [\"models/gemini-pro\", \"models/gemini-1.5-pro\", \"models/gemini-2.5-flash-preview-04-17\"]\n",
        "    model_options = [\"gemini-pro\", \"gemini-1.5-pro\", \"gemini-2.5-flash-preview-04-17\"]\n",
        "    model_mapping = {\"gemini-pro\": \"models/gemini-pro\", \"gemini-1.5-pro\": \"models/gemini-1.5-pro\", \"gemini-2.5-flash-preview-04-17\": \"models/gemini-2.5-flash-preview-04-17\"}\n",
        "\n",
        "# @markdown Enter video topic. Example: survival video game\n",
        "topic = \"Cooking secrets\" # @param {type:\"string\"}\n",
        "# @markdown video time in seconds\n",
        "time = \"30\" # @param {type:\"string\"}\n",
        "# @markdown video language\n",
        "language = \"english\" # @param [\"english\", \"spanish\", \"french\", \"german\", \"italian\", \"portuguese\", \"russian\", \"japanese\", \"korean\", \"chinese\"]\n",
        "# @markdown Use multiple speakers in video\n",
        "multi_speaker = \"no\" # @param [\"yes\",\"no\"]\n",
        "# @markdown get API from www.pexels.com\n",
        "pexels_api = \"\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown Use Gemini API for enhanced script generation (optional, strongly recommended)\n",
        "use_gemini = \"yes\" # @param [\"yes\",\"no\"]\n",
        "# @markdown Gemini API Key\n",
        "GEMINI_API_KEY = \"\" #@param {type:\"string\"}\n",
        "# @markdown Select Gemini model (display name without 'models/' prefix)\n",
        "GEMINI_MODEL_DISPLAY = model_options[0] if model_options else \"gemini-2.5-flash-preview-04-17\" #@param {type:\"string\"}\n",
        "# @markdown Optional: Enter a custom Gemini model name if it's not in the dropdown list\n",
        "CUSTOM_GEMINI_MODEL = \"\" #@param {type:\"string\"}\n",
        "# @markdown Check this if your custom model requires the v1beta API endpoint\n",
        "CUSTOM_MODEL_USES_BETA = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Process custom model input if provided\n",
        "if CUSTOM_GEMINI_MODEL:\n",
        "    print(f\"Using custom model: {CUSTOM_GEMINI_MODEL}\")\n",
        "    # Ensure the model has the 'models/' prefix if not already present\n",
        "    if not CUSTOM_GEMINI_MODEL.startswith(\"models/\"):\n",
        "        GEMINI_MODEL_NAME = f\"models/{CUSTOM_GEMINI_MODEL}\"\n",
        "    else:\n",
        "        GEMINI_MODEL_NAME = CUSTOM_GEMINI_MODEL\n",
        "else:\n",
        "    # Get the actual full model name with prefix from our mapping\n",
        "    GEMINI_MODEL_NAME = model_mapping.get(GEMINI_MODEL_DISPLAY, \"models/gemini-2.5-flash-preview-04-17\")\n",
        "    \n",
        "print(f\"Selected model: {GEMINI_MODEL_NAME.replace('models/', '')} (Full API name: {GEMINI_MODEL_NAME})\")\n",
        "\n",
        "# Update config.txt with Gemini API Key and model from form\n",
        "gemini_api_key_from_form = GEMINI_API_KEY # Gets value from the form field\n",
        "gemini_model_from_form = GEMINI_MODEL_NAME # Gets full model name with prefix\n",
        "use_gemini_setting = \"yes\" if use_gemini == \"yes\" else \"no\"\n",
        "\n",
        "# Check for temp API key from cell 2\n",
        "if not gemini_api_key_from_form and \"GEMINI_API_KEY_TEMP\" in os.environ:\n",
        "    gemini_api_key_from_form = os.environ[\"GEMINI_API_KEY_TEMP\"]\n",
        "    print(f\"Using Gemini API Key from previous cell\")\n",
        "\n",
        "if gemini_api_key_from_form and use_gemini_setting == \"yes\":\n",
        "    print(f\"Configuring Gemini with model: {gemini_model_from_form}\")\n",
        "    config_path = \"/content/UnQTube-/config.txt\"\n",
        "    try:\n",
        "        with open(config_path, \"r\") as f_read:\n",
        "            lines = f_read.readlines()\n",
        "        \n",
        "        updated_lines = []\n",
        "        key_updated = False\n",
        "        model_updated = False\n",
        "        gemini_enabled = False\n",
        "\n",
        "        for line in lines:\n",
        "            stripped_line = line.strip()\n",
        "            if stripped_line.startswith(\"gemini_api\"):\n",
        "                updated_lines.append(f\"gemini_api = {gemini_api_key_from_form}\\n\")\n",
        "                key_updated = True\n",
        "            elif stripped_line.startswith(\"gemini_model\"):\n",
        "                updated_lines.append(f\"gemini_model = {gemini_model_from_form}\\n\")\n",
        "                model_updated = True\n",
        "            elif stripped_line.startswith(\"use_gemini\"):\n",
        "                updated_lines.append(f\"use_gemini = {use_gemini_setting}\\n\")\n",
        "                gemini_enabled = True\n",
        "            else:\n",
        "                updated_lines.append(line)\n",
        "        \n",
        "        # If keys were not in original file, add them\n",
        "        if not key_updated:\n",
        "            updated_lines.append(f\"gemini_api = {gemini_api_key_from_form}\\n\")\n",
        "        if not model_updated:\n",
        "            updated_lines.append(f\"gemini_model = {gemini_model_from_form}\\n\")\n",
        "        if not gemini_enabled:\n",
        "            updated_lines.append(f\"use_gemini = {use_gemini_setting}\\n\")\n",
        "\n",
        "        with open(config_path, \"w\") as f_write:\n",
        "            f_write.writelines(updated_lines)\n",
        "        print(f\"Updated config.txt with Gemini settings\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Could not update config: {e}\")\n",
        "else:\n",
        "    # Ensure Gemini is disabled if no key is provided or user disabled it\n",
        "    print(f\"Gemini AI is {'disabled' if use_gemini_setting == 'no' else 'enabled but missing API key'}\")\n",
        "    config_path = \"/content/UnQTube-/config.txt\"\n",
        "    try:\n",
        "        with open(config_path, \"r\") as f_read:\n",
        "            lines = f_read.readlines()\n",
        "        \n",
        "        updated_lines = []\n",
        "        for line in lines:\n",
        "            stripped_line = line.strip()\n",
        "            if stripped_line.startswith(\"gemini_api\"):\n",
        "                updated_lines.append(\"gemini_api = \\n\") \n",
        "            elif stripped_line.startswith(\"use_gemini\"):\n",
        "                updated_lines.append(\"use_gemini = no\\n\")\n",
        "            else:\n",
        "                updated_lines.append(line)\n",
        "        \n",
        "        with open(config_path, \"w\") as f_write:\n",
        "            f_write.writelines(updated_lines)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Could not update config: {e}\")\n",
        "\n",
        "# Run the video generation command\n",
        "!python short.py -topic \"$topic\" -time \"$time\" -language \"$language\" -multi_speaker \"$multi_speaker\" -pexels_api \"$pexels_api\"\n",
        "\n",
        "# Display and offer download of the generated video\n",
        "from IPython.display import HTML, Video\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "output_file = \"/content/UnQTube_short.mp4\"\n",
        "\n",
        "if os.path.exists(output_file):\n",
        "    print(f\"\\n\\nShort video generation completed! File: {output_file}\")\n",
        "    \n",
        "    # Display the video\n",
        "    display(Video(output_file, width=600))\n",
        "    \n",
        "    # Offer download\n",
        "    try:\n",
        "        files.download(output_file)\n",
        "    except Exception as e:\n",
        "        print(f\"\\nTo download the video, use the three-dot menu in the file browser panel and select '{output_file}'\")\n",
        "else:\n",
        "    print(\"\\n\\nNo video file was generated. Check the output above for errors.\")"
    ],
    "execution_count": None,
    "outputs": []
}

# Create notebook structure
notebook = {
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        system_setup_cell,
        dependencies_cell,
        gemini_config_cell,
        long_video_cell,
        short_video_cell
    ]
}

# Save notebook
with open('UnQTube_Colab.ipynb', 'w') as f:
    json.dump(notebook, f, indent=2)

print("Enhanced notebook created successfully as UnQTube_Colab.ipynb") 